

{\tiny **Abstract**  Load imbalances across cores of a multicore node on a supercomputer slow down applications significantly. In addition, such imbalances have been shown to slow down applications dramatically as the number of nodes used by them is increased. Although dynamic load balancing within a multicore node can mitigate these problems in principle, such balancing is challenging because of its impact on data movement and synchronization overhead. In this talk, I first discuss the aforementioned challenge and shortcomings of solutions that use available OpenMP loop schedules. Then, I discuss a series of novel loop scheduling strategies that mitigate node-local load imbalances without incurring high overheads. The underlying methodology helps speed up applications on supercomputers with minimal application programmer intervention. We expect that these techniques will be useful for future extreme-scale supercomputers. Finally, I discuss work on combining my loop scheduling strategies with other performance optimizations and for making them easy-to-use. Specifically, I describe: (a) a proposal for a User-Defined Schedule clause for OpenMP that can support myriad efficient loop scheduling strategies, including application-specific ones; (b) the use of my loop scheduling strategies as a policy in LLNLâ€™s RAJA framework; and (c) a technique that combines my intra-node loop scheduling strategies with inter-node load balancing strategies in the Charm++ runtime system.}